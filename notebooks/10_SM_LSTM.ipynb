{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7ecd2bc-4938-4c9b-93b9-51b239b81547",
   "metadata": {},
   "source": [
    "# Soil Moisture Simulation LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8ebe98b-fa18-45a4-8b1e-5cd6cdff04e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np \n",
    "import xarray as xr \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings \n",
    "import pandas as pd\n",
    "import torch \n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/tommy/neuralhydrology\")\n",
    "from scripts.read_nh_results import (\n",
    "    get_test_filepath,\n",
    "    get_all_station_ds,\n",
    "    calculate_all_error_metrics,\n",
    "    get_ensemble_path,\n",
    ")\n",
    "\n",
    "from scripts.read_model import (get_model, _load_weights)\n",
    "from scripts.read_nh_results import (read_multi_experiment_results, calculate_member_errors)\n",
    "from neuralhydrology.utils.config import Config\n",
    "\n",
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c25765e-1541-4156-9f95-9ef5be099fbe",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f354aab3-e6ba-483f-80fb-a2f83234ba06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f90a6f2-1dbf-4ec2-a779-d6798d757a9a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Has validation been run? ipython --pdb neuralhydrology/nh_run.py evaluate -- --run-dir /datadrive/data/runs/ERA5Land_SoilMoisture/ERA5Land_SoilMoistureVolumeLevel1_1108_202913",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ad2bbfae8715>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# GET preds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mres_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_test_filepath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_multi_experiment_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpt_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensemble_members\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/neuralhydrology/scripts/read_nh_results.py\u001b[0m in \u001b[0;36mget_test_filepath\u001b[0;34m(run_dir, epoch)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mres_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"test_results.p\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     assert (\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0mres_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     ), f\"Has validation been run? ipython --pdb neuralhydrology/nh_run.py evaluate -- --run-dir {run_dir.absolute()}\"\n",
      "\u001b[0;31mAssertionError\u001b[0m: Has validation been run? ipython --pdb neuralhydrology/nh_run.py evaluate -- --run-dir /datadrive/data/runs/ERA5Land_SoilMoisture/ERA5Land_SoilMoistureVolumeLevel1_1108_202913"
     ]
    }
   ],
   "source": [
    "run_dir = Path(\"/datadrive/data/runs/esa_cci_sm_lstm_1406_114743\")\n",
    "run_dir = Path(\"/datadrive/data/runs/esa_cci_sm_SMOOTH_lstm_2106_153936\")\n",
    "expt_dir = Path(\"/datadrive/data/runs/ERA5Land_SoilMoisture\")\n",
    "\n",
    "run_dir = sorted(list(expt_dir.iterdir()))[0]\n",
    "\n",
    "# GET config\n",
    "cfg = Config(run_dir / \"config.yml\")\n",
    "cfg.run_dir = run_dir\n",
    "\n",
    "# GET preds\n",
    "res_fp = get_test_filepath(run_dir, epoch=30)\n",
    "\n",
    "preds = read_multi_experiment_results(expt_dir, ensemble_members=False)\n",
    "preds = preds.sortby(\"member\")\n",
    "preds[\"member\"] = [\"swvl1\", \"swvl2\", \"swvl3\", \"swvl4\"]\n",
    "\n",
    "# GET trained model\n",
    "model = get_model(cfg).to(cfg.device)\n",
    "_load_weights(model, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71879223-bfae-408f-870e-816f5a2d6934",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"/datadrive/data\")\n",
    "preds.to_netcdf(data_dir / \"SOIL_MOISTURE/results/lstm_direct_sm_preds.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f833517c-1026-41b8-b73c-9efd15c6a74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_var=[v for v in preds.data_vars if \"obs\" in v][0]\n",
    "sim_var=[v for v in preds.data_vars if \"sim\" in v][0]\n",
    "\n",
    "sm_errors = calculate_member_errors(\n",
    "    preds,\n",
    "    basin_coord=\"station_id\",\n",
    "    time_coord=\"time\",\n",
    "    obs_var=obs_var,\n",
    "    sim_var=sim_var,\n",
    "    metrics=[\"NSE\", \"Pearson-r\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafa3cab-6852-47d9-a4a6-2da6bb3fd1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unq_vars = np.unique([\"_\".join(v.split(\"_\")[0:-1]) for v in preds.data_vars])\n",
    "from scripts.cell_state.analysis import finite_flat, histogram_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ba9431-c50b-4c53-a045-29d69e0aa8ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "variable = \"Pearson-r\"\n",
    "f, axs = plt.subplots(2, 1, figsize=(12, 4*2))\n",
    "\n",
    "colors = sns.color_palette(\"viridis\", 4)\n",
    "for jx, member in enumerate(preds.member.values):\n",
    "    color = colors[jx]\n",
    "    for i, variable in enumerate([\"NSE\", \"Pearson-r\"]):\n",
    "        ax = axs[i]\n",
    "        arr = finite_flat(sm_errors[variable].sel(member=member))\n",
    "        med = np.median(arr)\n",
    "        histogram_plot(np.clip(arr, 0, 1), hist_kwargs={\"color\": color, \"label\": f\"{member}: {med:.2f}\"}, ax=ax)\n",
    "        ax.legend()\n",
    "        ax.set_xlabel(variable)\n",
    "        ax.set_xlim(0, 1)\n",
    "        if i == 0:\n",
    "            ax.set_title(\"The Single-Output LSTM SM simulations produce NSE scores comparable with discharge\")\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ef4ff3-2d11-4f36-ad74-1c7ca5e1cd1c",
   "metadata": {},
   "source": [
    "# How does it compare with the probe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1e87bd-3d6c-44fc-832a-dd7865fae629",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.cell_state.analysis import (save_probe_components, load_probe_components)\n",
    "\n",
    "probe_run_dir = Path('/datadrive/data/runs/complexity_AZURE/hs_064_0306_205514')\n",
    "all_models_preds = load_probe_components(probe_run_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955e448a-636d-44cb-9ae3-535bafd39fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def empirical_cdf(errors: np.ndarray, kwargs: Dict[str, Any] = {}):\n",
    "    x = np.sort(errors)\n",
    "    y = np.arange(len(x))/float(len(x))\n",
    "    plt.plot(x, y, **kwargs)\n",
    "\n",
    "    \n",
    "f, ax = plt.subplots(figsize=(12, 4))\n",
    "# nse = sm_errors[\"NSE\"]\n",
    "# empirical_cdf(nse, kwargs={\"label\": f\"SWVL1 LSTM: {np.median(nse):.2f}\", \"color\": \"C0\"})\n",
    "\n",
    "# plot probe results\n",
    "target_vars = list(all_models_preds.keys())\n",
    "colors = sns.color_palette(\"viridis\", n_colors=len(target_vars))\n",
    "for ix, target_var in enumerate(target_vars):\n",
    "    errors = all_models_preds[target_var][\"errors\"]\n",
    "    nse = errors[\"NSE\"]\n",
    "    empirical_cdf(nse, kwargs={\"label\": f\"Probe {target_var}: {np.median(nse):.2f}\", \"color\": colors[ix], \"ls\": \"--\"})\n",
    "    \n",
    "    lstm_nse = sm_errors.sel(member=target_var)[\"NSE\"]\n",
    "    empirical_cdf(lstm_nse, kwargs={\"label\": f\"{target_var} LSTM: {np.median(lstm_nse):.2f}\", \"color\": colors[ix]})\n",
    "\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1.1)\n",
    "plt.legend()\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0669bf-6b71-41f3-93dc-0ae80f1ad247",
   "metadata": {},
   "source": [
    "# Timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6c3788-a441-4df2-b358-b96b810f9ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels = np.random.choice(preds.station_id.values, size=10)\n",
    "\n",
    "times = slice(\"04-01-2000\", \"01-01-2010\")\n",
    "\n",
    "f, axs = plt.subplots(len(pixels), 1, figsize=(12, 4*len(pixels)))\n",
    "member = \"swvl1\"\n",
    "for i, px in enumerate(pixels):\n",
    "    ax = axs[i]\n",
    "    preds.sel(station_id=px, member=member)[obs_var].sel(time=times).plot(ax=ax, color=\"k\", alpha=0.6, ls=\"--\", label=f\"{member} Obs\")\n",
    "    preds.sel(station_id=px, member=member)[sim_var].sel(time=times).plot(ax=ax, label=f\"LSTM {member}\", color=\"C2\")\n",
    "    ax.legend()\n",
    "    sns.despine()\n",
    "    \n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0526b0-999e-4803-8e89-35e9f4107967",
   "metadata": {},
   "source": [
    "# Spatial Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015f9c0b-6eb0-470e-b21c-2ab30af676bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from scripts.geospatial import initialise_gb_spatial_plot, load_latlon_points\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "st_data_dir = Path(\"/home/tommy/spatio_temporal/data\")\n",
    "points = load_latlon_points(st_data_dir)\n",
    "static = xr.open_dataset(st_data_dir / \"camels_static.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bd1386-965b-4462-b1fb-15d784e6f853",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_errors[\"station_id\"] = sm_errors[\"station_id\"].astype(int)\n",
    "\n",
    "for member in sm_errors.member.values:\n",
    "    err_ = sm_errors.sel(member=member)\n",
    "    gdf = gpd.GeoDataFrame(err_.to_dataframe().join(points))\n",
    "\n",
    "    ax = initialise_gb_spatial_plot()\n",
    "    gdf.plot(\"NSE\", vmin=0.7, vmax=1, ax=ax, cmap=\"viridis_r\", legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecca130-c73a-4455-9372-5ad81db533a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
